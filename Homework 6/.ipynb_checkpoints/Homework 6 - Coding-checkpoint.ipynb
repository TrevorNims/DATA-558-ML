{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "greek-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-rebate",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "upper-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data, separate features into X and Y\n",
    "\n",
    "file = 'default_plus_chromatic_features_1059_tracks.txt'\n",
    "dat = pd.read_csv(file, header=None)\n",
    "X = dat.iloc[:,:-2]\n",
    "y, orig = pd.factorize(dat.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "breathing-prime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-0.364194</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>0.936616</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>0.603755</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>0.187169</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>1.620715</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1  0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2 -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3 -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4  0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "\n",
       "        7         8         9    ...       108       109       110       111  \\\n",
       "0 -1.205671  1.849122 -0.425598  ... -0.364194 -0.364194 -0.364194 -0.364194   \n",
       "1 -0.887385  0.432062 -0.093963  ...  0.936616  0.936616  0.936616  0.936616   \n",
       "2 -0.694895 -0.901869 -1.701574  ...  0.603755  0.603755  0.603755  0.603755   \n",
       "3  0.114752  0.692847  0.052377  ...  0.187169  0.187169  0.187169  0.187169   \n",
       "4 -0.401676 -0.872639  1.147483  ...  1.620715  1.620715  1.620715  1.620715   \n",
       "\n",
       "        112       113       114       115    116    117  \n",
       "0 -0.364194 -0.364194 -0.364194 -0.364194 -15.75 -47.95  \n",
       "1  0.936616  0.936616  0.936616  0.936616  14.91 -23.51  \n",
       "2  0.603755  0.603755  0.603755  0.603755  12.65  -8.00  \n",
       "3  0.187169  0.187169  0.187169  0.187169   9.03  38.74  \n",
       "4  1.620715  1.620715  1.620715  1.620715  34.03  -6.85  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out head of data (for fun!)\n",
    "\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-arcade",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "studied-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 80/20 train test set split, standardize X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "initial-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct empircal covariance matrix using X_train\n",
    "\n",
    "cov_matrix = 1/(X_train.shape[0]-1)*np.dot(X_train.T, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-feeding",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "alike-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define power iteration algorithm\n",
    "\n",
    "def power_iter_algo(A, max_iter):\n",
    "    v = np.random.normal(size=A.shape[0])\n",
    "    for i in range(max_iter):\n",
    "        z = np.dot(A, v)\n",
    "        v = z/np.linalg.norm(z, ord=2)\n",
    "    lambda_ = np.dot(np.dot(v.T, A), v)\n",
    "    return lambda_, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "postal-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run power iteration on empircal covariance matrix\n",
    "\n",
    "e_val, e_vec = power_iter_algo(cov_matrix, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-delivery",
   "metadata": {},
   "source": [
    "## (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "surprising-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute top eigenvalue, eigenvector using numpy\n",
    "\n",
    "e_vals, e_vecs = np.linalg.eig(cov_matrix)\n",
    "pc_order = np.argsort(e_vals)[::-1]\n",
    "\n",
    "top_val = e_vals[pc_order[0]]\n",
    "top_vec = e_vecs[:, pc_order[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "chief-gather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top eigenvalue via power iteration: 44.84313416764799 \n",
      "Top eigenvalue via numpy: 44.84313416764802\n",
      "Two norm of difference of each method's top eigenvectors: 5.029298353511653e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trevornims/opt/anaconda3/envs/DATA558/lib/python3.7/site-packages/ipykernel_launcher.py:3: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Compare results to power iteration alogrithm\n",
    "\n",
    "print('Top eigenvalue via power iteration:', e_val, '\\nTop eigenvalue via numpy:', float(top_val))\n",
    "print('Two norm of difference of each method\\'s top eigenvectors:', np.linalg.norm(e_vec-top_vec, ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-worry",
   "metadata": {},
   "source": [
    "As can be seen above, the power iteration algorithm obtains values very close to the truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-custody",
   "metadata": {},
   "source": [
    "## (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "diagnostic-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deflate covariance matrix, compute second largest eigenvector and eigenvalue using power\n",
    "# iteration\n",
    "\n",
    "cov_deflate = cov_matrix - e_val*np.outer(e_vec, e_vec)\n",
    "\n",
    "e_val_2, e_vec_2 = power_iter_algo(cov_deflate, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "hairy-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd largest eigenvalue via power iteration: 12.553125465320704 \n",
      "2nd largest eigenvalue via numpy: 12.553125465320738\n",
      "Two norm of difference of each method's 2nd largest eigenvectors: 1.8795562878978943e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trevornims/opt/anaconda3/envs/DATA558/lib/python3.7/site-packages/ipykernel_launcher.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Compare to numpy's implementation\n",
    "\n",
    "print('2nd largest eigenvalue via power iteration:', e_val_2, '\\n2nd largest eigenvalue via numpy:', \n",
    "      float(e_vals[pc_order[1]]))\n",
    "print('Two norm of difference of each method\\'s 2nd largest eigenvectors:', \n",
    "      np.linalg.norm(-e_vec_2-e_vecs[:, pc_order[1]], ord=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-whole",
   "metadata": {},
   "source": [
    "Again, as can be seen above, the power iteration algorithm obtains values very close to the truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-kentucky",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-blanket",
   "metadata": {},
   "source": [
    "An approach to compute the $k^{th}$ largest eigenvector of $X$ could be done through the following procedure:\n",
    "\n",
    "   1. Compute the largest eigenvector, eigenvalue of $X$ with power iteration\n",
    "    \n",
    "   2. Deflate $X$\n",
    "    \n",
    "   3. Repeat process with deflated $X$ $k-1$ times\n",
    "\n",
    "This algorithm is coded up below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "classified-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for approximating the kth largest eigenvector of a matrix X\n",
    "\n",
    "def kth_eig(X, k):\n",
    "    X_cp = np.copy(X)\n",
    "    for i in range(k-1):\n",
    "        e_val, e_vec = power_iter_algo(X_cp, max_iter=100)\n",
    "        X_cp = X_cp - e_val*np.outer(e_vec, e_vec)\n",
    "    e_val, e_vec = power_iter_algo(X_cp, max_iter=100)\n",
    "    return e_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "solid-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two norm of difference of each method's 5th largest eigenvectors: 5.225366028792415e-05\n"
     ]
    }
   ],
   "source": [
    "# Check if it works\n",
    "\n",
    "k = 5\n",
    "\n",
    "estimate = kth_eig(cov_matrix, k)\n",
    "print('Two norm of difference of each method\\'s 5th largest eigenvectors:', \n",
    "      np.linalg.norm(estimate-e_vecs[:, pc_order[4]], ord=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-journey",
   "metadata": {},
   "source": [
    "As can be seen above, it looks like the algorithm is decent (up to an okay level of precision) at estimating the $k^{th}$ largest eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-framing",
   "metadata": {},
   "source": [
    "## (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fatty-radius",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trevornims/opt/anaconda3/envs/DATA558/lib/python3.7/site-packages/ipykernel_launcher.py:3: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/trevornims/opt/anaconda3/envs/DATA558/lib/python3.7/site-packages/ipykernel_launcher.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Compute reduced-dimensionality version of X_train, X_test by projecting them onto the top 20 principal components\n",
    "\n",
    "X_train_20 = np.dot(X_train, e_vecs[:, pc_order[:20]].astype(np.float))\n",
    "X_test_20 = np.dot(X_test, e_vecs[:, pc_order[:20]].astype(np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-helena",
   "metadata": {},
   "source": [
    "## (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "sunset-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 1-NN models on original train data and projected train data\n",
    "\n",
    "knn_original = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)\n",
    "knn_PCA = KNeighborsClassifier(n_neighbors=1).fit(X_train_20, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-slave",
   "metadata": {},
   "source": [
    "## (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "sweet-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN model fit on original training data obtained a test accuracy score of: 0.36792452830188677 \n",
      "1-NN model fit on the projected data obtained a test accuracy score of: 0.35377358490566035\n"
     ]
    }
   ],
   "source": [
    "# Print both model's classification accuracy on test data\n",
    "\n",
    "print(\"1-NN model fit on original training data obtained a test accuracy score of:\", \n",
    "      knn_original.score(X_test, y_test), \n",
    "      \"\\n1-NN model fit on the projected data obtained a test accuracy score of:\",\n",
    "      knn_PCA.score(X_test_20, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-toolbox",
   "metadata": {},
   "source": [
    "As can be seen above, despite removing more than 80% of the features, the PCA model still did quite well in fitting a model to the data. That being said, it was still outperformed by the model that was trained using all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-particular",
   "metadata": {},
   "source": [
    "## (j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-baltimore",
   "metadata": {},
   "source": [
    "Instead of stopping the updates after a maximum number of iterations, it might be more \"sophisticated\" to pass a tolerance parameter to our algorithm, causing it to stop iterating only once the change in the value of the eigenvector has decreased past the tolerance threshold. A possible implementation is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "separate-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sophisticated version of algorithm with a revised stopping condition, returns approximated eigenvectors and\n",
    "# eigenvalues as well as an iteration count (for fun!)\n",
    "\n",
    "def power_iter_improved(A, epsilon):\n",
    "    v = np.random.normal(size=A.shape[0])\n",
    "    z = np.dot(A, v)\n",
    "    count=0\n",
    "    while np.linalg.norm(v-z/np.linalg.norm(z, ord=2), ord=2) > epsilon:\n",
    "        v = z/np.linalg.norm(z, ord=2)\n",
    "        z = np.dot(A, v)\n",
    "        count += 1\n",
    "    lambda_ = np.dot(np.dot(v.T, A), v)\n",
    "    return lambda_, v, count\n",
    "\n",
    "\n",
    "val, vec, ct = power_iter_improved(cov_matrix, 1*10**-10)\n",
    "ct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DATA558] *",
   "language": "python",
   "name": "conda-env-DATA558-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
